{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l2\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):                           #function to read glove vectors\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7552</td>\n",
       "      <td>5080</td>\n",
       "      <td>7613</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>221</td>\n",
       "      <td>3341</td>\n",
       "      <td>7503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     keyword location  \\\n",
       "count    7613.000000        7552     5080   \n",
       "unique           NaN         221     3341   \n",
       "top              NaN  fatalities      USA   \n",
       "freq             NaN          45      104   \n",
       "mean     5441.934848         NaN      NaN   \n",
       "std      3137.116090         NaN      NaN   \n",
       "min         1.000000         NaN      NaN   \n",
       "25%      2734.000000         NaN      NaN   \n",
       "50%      5408.000000         NaN      NaN   \n",
       "75%      8146.000000         NaN      NaN   \n",
       "max     10873.000000         NaN      NaN   \n",
       "\n",
       "                                                     text      target  \n",
       "count                                                7613  7613.00000  \n",
       "unique                                               7503         NaN  \n",
       "top     11-Year-Old Boy Charged With Manslaughter of T...         NaN  \n",
       "freq                                                   10         NaN  \n",
       "mean                                                  NaN     0.42966  \n",
       "std                                                   NaN     0.49506  \n",
       "min                                                   NaN     0.00000  \n",
       "25%                                                   NaN     0.00000  \n",
       "50%                                                   NaN     0.00000  \n",
       "75%                                                   NaN     1.00000  \n",
       "max                                                   NaN     1.00000  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data1 = pd.read_csv(\"train.csv\")\n",
    "train = raw_data1.copy()\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      10873\n",
       "keyword                                                   NaN\n",
       "location                                                  NaN\n",
       "text        The Latest: More Homes Razed by Northern Calif...\n",
       "target                                                      1\n",
       "Name: 7612, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[7612]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data2 = pd.read_csv('test.csv')\n",
    "test = raw_data2.copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, #eart...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask., canada]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[all, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[13,000, people, receive, #wildfires, evacuati...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, #al...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  [our, deeds, are, the, reason, of, this, #eart...   \n",
       "1   4     NaN      NaN     [forest, fire, near, la, ronge, sask., canada]   \n",
       "2   5     NaN      NaN  [all, residents, asked, to, 'shelter, in, plac...   \n",
       "3   6     NaN      NaN  [13,000, people, receive, #wildfires, evacuati...   \n",
       "4   7     NaN      NaN  [just, got, sent, this, photo, from, ruby, #al...   \n",
       "\n",
       "   target  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].str.split()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(sentence_words):                               #removing punctuations\n",
    "    punctuations= list(\"?:!.,;#[({]})/@!$%^&*''\"\"\")\n",
    "    s = []\n",
    "    for word in sentence_words:\n",
    "        w = list(word)\n",
    "        t = []\n",
    "        for x in w:\n",
    "            if x not in punctuations:\n",
    "                t.append(x)\n",
    "        y = \"\".join(t)\n",
    "        s.append(wordnet_lemmatizer.lemmatize(y,pos='v'))              #lemmetize the given sentences\n",
    "    return (s)\n",
    "data['text'] = data['text'].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['location', 'keyword'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:7613]\n",
    "test = data.iloc[7613:]\n",
    "test = test.drop(['target'], axis=1)\n",
    "data_X = train.drop(['target','id'],axis=1)\n",
    "data_Y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['text'].to_numpy()\n",
    "X_test = X_test['text'].to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'roadid',\n",
       " 'thank',\n",
       " 'to',\n",
       " 'alex',\n",
       " 'for',\n",
       " 'his',\n",
       " 'story',\n",
       " 'amp',\n",
       " 'to',\n",
       " 'all',\n",
       " 'first',\n",
       " 'responders',\n",
       " 'for',\n",
       " 'be',\n",
       " 'there',\n",
       " 'when',\n",
       " 'we',\n",
       " 'need',\n",
       " 'you',\n",
       " '\\x89รป_',\n",
       " 'httptcohikdc1fm2f']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = len(max(data['text'], key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \n",
    "    m = X.shape[0]                                   \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):                              \n",
    "        sentence_words = [w.lower() for w in X[i]   \n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index.keys():\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            j += 1\n",
    "            \n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):      #Create keras embedding layer\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter(input_shape, word_to_vec_map, word_to_index):       #Function creating twitter model's graph\n",
    "\n",
    "    # Define sentence_indices as the input of the graph.\n",
    "    # It should be of shape input_shape and dtype 'int32' (as it contains indices, which are integers).\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    #pass input to embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices) \n",
    "    #pass through the fisrt LSTM model\n",
    "    X = LSTM(units=128, return_sequences=True,kernel_regularizer=l2(0.00005))(embeddings)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    #second LSTM layer\n",
    "    X = LSTM(units=128, return_sequences=False,kernel_regularizer=l2(0.0005))(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    # Hidden layer\n",
    "    X = Dense(1)(X)\n",
    "    X = Activation(activation='sigmoid')(X)\n",
    "    model = Model(inputs = sentence_indices, outputs = X)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 31)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 31, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 31, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,411\n",
      "Trainable params: 223,361\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = twitter((maxlen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.6398 - accuracy: 0.7119\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 11s 401ms/step - loss: 0.5191 - accuracy: 0.7952\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 10s 365ms/step - loss: 0.4866 - accuracy: 0.8011\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 10s 388ms/step - loss: 0.4713 - accuracy: 0.8005\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 10s 376ms/step - loss: 0.4588 - accuracy: 0.8053\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 13s 498ms/step - loss: 0.4500 - accuracy: 0.8120\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 11s 422ms/step - loss: 0.4407 - accuracy: 0.8156\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 9s 339ms/step - loss: 0.4383 - accuracy: 0.8161\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 11s 403ms/step - loss: 0.4212 - accuracy: 0.8231\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 9s 341ms/step - loss: 0.4140 - accuracy: 0.8305\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 9s 347ms/step - loss: 0.4063 - accuracy: 0.8329\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 12s 436ms/step - loss: 0.3991 - accuracy: 0.8342\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 9s 330ms/step - loss: 0.3894 - accuracy: 0.8453\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 9s 317ms/step - loss: 0.3787 - accuracy: 0.8479\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 8s 310ms/step - loss: 0.3806 - accuracy: 0.8440\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 8s 314ms/step - loss: 0.3692 - accuracy: 0.8486\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 8s 302ms/step - loss: 0.3527 - accuracy: 0.8602\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 9s 320ms/step - loss: 0.3455 - accuracy: 0.8667\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 10s 369ms/step - loss: 0.3381 - accuracy: 0.8692\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 11s 410ms/step - loss: 0.3249 - accuracy: 0.8748\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 8s 314ms/step - loss: 0.3192 - accuracy: 0.8796\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 10s 361ms/step - loss: 0.3020 - accuracy: 0.8850\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 10s 356ms/step - loss: 0.2885 - accuracy: 0.8921\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 8s 299ms/step - loss: 0.2753 - accuracy: 0.8996\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 9s 350ms/step - loss: 0.2703 - accuracy: 0.8996\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 11s 401ms/step - loss: 0.2768 - accuracy: 0.8983\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 8s 300ms/step - loss: 0.2687 - accuracy: 0.8991\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 10s 359ms/step - loss: 0.2542 - accuracy: 0.9085\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 11s 420ms/step - loss: 0.2388 - accuracy: 0.9149\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 8s 313ms/step - loss: 0.2304 - accuracy: 0.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144ad0c50>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, y_train, epochs = 30, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 29ms/step - loss: 0.6876 - accuracy: 0.7979\n",
      "\n",
      "Test accuracy =  0.7979002594947815\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxlen)\n",
    "loss, acc = model.evaluate(X_test_indices, y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(test['text'], word_to_index, max_len = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.rint(pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test1['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
